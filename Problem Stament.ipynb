{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_PS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cgl8LFlwrPh",
        "colab_type": "text"
      },
      "source": [
        "This aim of this Problem Statement is to introduce Deep Learning, which is one of the most used techniques for Computer Vision Application. \n",
        "Before beginning go thorugh the following articles:\n",
        "1. https://www.nature.com/articles/nature14539 : It is fairly easy to follow and provides an excellent overview of the field. (You will need to login with smail to download the pdf.) \n",
        "\n",
        "2. http://deeplearning.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/ : A short introduction to Multi-layer perceptrons.\n",
        "\n",
        "3. https://cs231n.github.io/convolutional-networks/ : Introduction to Convolutional Neural Networks. CNNs are generally used for computer vision problems.\n",
        "\n",
        "\n",
        "This introduction should be sufficient to get you started with this problem statement. If after going through the PS, you guys are interested in further exploring the field, I would suggest the following resources:\n",
        "1. http://cs231n.stanford.edu/ : Online course by Stanford.\n",
        "2. http://introtodeeplearning.com/: Video Lectures from MIT\n",
        "3. https://www.deeplearningbook.org/: Most popular book on Deep Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PysRfCI1eQy",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "The aim of this get you all familiarized with Deep Learning in PyTorch, a very popular Deep Learning Library (or in general GPU computation library).\n",
        "\n",
        "Some of the preprocessing work has been done, and you guys are expected to fill-in code where you are asked to. \n",
        "\n",
        "In this notebook we will be doing the following tasks:\n",
        "1.   Define a small convolutional neural network and train in on MNIST digit dataset (as a classification task).\n",
        "2.   Take the trained network, freeze all of its weights and learn the image which gives the output of a particular digit. (This will be defined better, when we reach that task).\n",
        "3.   (Bonus) Try the same on a different dataset (like MNIST fashion dataset).\n",
        "4.   (Bonus) Try to formulate the MNIST classification problem as a regression problem instead. (i.e. Have 1 output unit which outputs a floating point value and you round it off to obtain the digit.)\n",
        "\n",
        "\n",
        "Before diving into the code ensure that you copy the notebook to your drive (See the option in File Tab) and that the Runtime Type is set to GPU (Runtime tab -> Change runtime type). To see the importance of GPU in deep learning see [this](https://course.fast.ai/gpu_tutorial.html) short article.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5-IM6RV6ROj",
        "colab_type": "text"
      },
      "source": [
        "The following cell imports all the necessary packages. We will be using :\n",
        "1. Several Modules of PyTorch. This will be used to do all the processing and importing the dataset etc. Read [this](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) and [this](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html) article to get started. Here are the [official docs](https://pytorch.org/docs/stable/index.html).\n",
        "\n",
        "2. NumPy is likely the most popular Matrix manipulation and linear algebra library available for Python. Unfortunately it does not support processing on GPU and therefore we will not be using it much here (Only as a support library for matplotlib). Here is a quick [tutorial](https://cs231n.github.io/python-numpy-tutorial/) if you are interested. \n",
        "\n",
        "3. Matplotlib is the most popular library for generating plots in Python. We will be using it for printing images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNntDX8oAsDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch \n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "#This to ensure that the default device for processing PyTorch tensors is GPU instead of a CPU.\n",
        "device = 'cuda' #Change this to 'cpu' to run on cpu. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfynPVQmAZL9",
        "colab_type": "text"
      },
      "source": [
        "Here we will download the MNIST digit dataset and convert it into PyTorch dataset object. \n",
        "\n",
        "torchvision module of PyTorch provides several Computer Vision specific functionalities one of which is easy importing of several [popular datasets](https://pytorch.org/docs/stable/torchvision/datasets.html). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPT0_Ob9BDUG",
        "colab_type": "code",
        "outputId": "286543a5-41b1-4434-c335-96839438892d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "source": [
        "#We will load the MNIST dataset here.\n",
        "\n",
        "#This creates a transform object which will be passed to the later functions. It converts the training image from PIL Image objects to PyTorch image objects.\n",
        "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "\n",
        "train_data = torchvision.datasets.MNIST(root = './data', train = True, download = True, transform = transform )\n",
        "\n",
        "test_data = torchvision.datasets.MNIST(root = './data',train = False ,download = True,  transform = transform)\n",
        "\n",
        " \n",
        "\n",
        "print(train_data)\n",
        "print(test_data)\n",
        "\n",
        "plt.imshow(np.asarray(train_data[1][0].reshape(28,28)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: ./data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "           )\n",
            "Dataset MNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: ./data\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "           )\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f293af022b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpqZ4LD-F0SH",
        "colab_type": "text"
      },
      "source": [
        "The following cell converts the DataSet objects to DataLoader objects. \n",
        "DataLoader objects in PyTorch provide several useful functionalities, such as automatic batching, parallel data processing on the CPU, etc. Therefore it is generally advisable to use dataloader instead of manually handling data. \n",
        "\n",
        "Read more about PyTorch DataSet and DataLoader [here](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRmiRtSDB_QV",
        "colab_type": "code",
        "outputId": "742c6b79-d308-46b4-e05a-11b5c40c10ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#BATCHs are only used for training, while testing we conventionally use a batch size of 1.  \n",
        "BATCH_SIZE = 32 \n",
        "train_loader = torch.utils.data.DataLoader (train_data, batch_size = BATCH_SIZE, )\n",
        "test_loader = torch.utils.data.DataLoader (test_data, batch_size = 1, )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(train_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7f293af0c400>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMeoiIqrd-v7",
        "colab_type": "text"
      },
      "source": [
        "**TASK 1**\n",
        "\n",
        "We will define our network in the following cell. There are several ways of doing this in PyTorch, but in this example we will do it by subclassing nn.module. You should be able to do this after reading the tutorials given at the top of the page. [This](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) is extra reading to help you out. (Do remember that we are dealing with 1 channel B/W images not 3 channels colour images.)\n",
        "\n",
        "[Here](https://pytorch.org/docs/stable/nn.html) are official docs of nn module to help you out. \n",
        "\n",
        "Our network will have 4 convolutional layers followed by 2 fully-connected layers. (You free to change make slight changes to this but don't make the network too deep in the final submission). \n",
        "\n",
        "Don't forget to have ReLU activations and maxpooling layers.\n",
        "\n",
        "Experiment with different kernal sizes, width and sizes of hidden fully connected units. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHW6Cku-CJSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Complete the functions __init__ and forward below\n",
        "\n",
        "class MyConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    \"\"\" \n",
        "      Initialize all the weights for each layer you require.\n",
        "\n",
        "    \"\"\"    \n",
        "    super(MyConvNet, self).__init__()\n",
        "    # Put your code here: \n",
        "    # __begin\n",
        "    \n",
        "  \n",
        "    #__end\n",
        "  def forward (self, x):\n",
        "    \"\"\"\n",
        "    Define a forward pass for the given network. x is a 4 dimentional input tensor. \n",
        "    Input: x.size() = [BATCH_SIZE, 1, 28, 28]\n",
        "\n",
        "    Return a 2-dimentional, 10-unit output tensor representing the probability of each class. Use a softmax output unit.\n",
        "    Output: x.size() = [BATCH_SIZE, 10] \n",
        "    \"\"\"\n",
        "    # Put your code here: \n",
        "    # __begin\n",
        "   \n",
        "    \n",
        "    #__end\n",
        "    #Return statement uses softmax, so after the final fully connected layer store the value in x (without using ReLU or any other activation).\n",
        "    return F.softmax(x, dim = 1) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05mzNPxSPIXu",
        "colab_type": "text"
      },
      "source": [
        "The following cell will instantiate the the network we defined above.\n",
        "Check the size of the output tensor (it should be [BATCH_SIZE, 10]) and see if the values in the output tensor printed below are numbers between 0 and 1. (Infact most values should be close to 0.1. Why?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8ia3HNIN3B2x",
        "colab": {}
      },
      "source": [
        "#Setting few things up.\n",
        "\n",
        "net = MyConvNet()\n",
        "net.to(device)\n",
        "print(net)\n",
        "tld = iter(train_loader)\n",
        "im = next(tld)[0].to(device)\n",
        "print ('Size of the output tensor:' ,net.forward(im).size())\n",
        "print (net.forward(im))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xIdHy0wRMX1",
        "colab_type": "text"
      },
      "source": [
        "The following cell will define the training and the testing loop. \n",
        "\n",
        "\n",
        "I have already defined the training loop to give you guys some idea. Try changing the learning rates, EPOCHS, weight_decay, and optimizers etc. to see how the learning process changes.\n",
        "\n",
        "\n",
        "Your task is to define the test function which prints the test accuracy, given the model and test_loader. Do remember that while testing we use a single image (batch of size 1). \n",
        "\n",
        "First understand the train function properly. Then attempt to write the test function.\n",
        "\n",
        "(HINT: you don't need optimizer (torch.optim) and loss fucntion (nn.CrossEntropyLoss) for testing).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYgE1F24lXn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_loader, EPOCHS = 6, lossF = None):\n",
        "  \n",
        "  if lossF == None:\n",
        "    lossF = nn.CrossEntropyLoss() #Cross entropy loss is popularly used for classification tasks. \n",
        "  \n",
        "  ## Adam is a very popular choice of optimization algorithms. \n",
        "  ## It is not very sensitive to hyperparameters and therefore it becomes a natural choice in quick experiments.\n",
        "  optim = torch.optim.Adam (model.parameters(), lr = 4e-4, weight_decay=1e-3) \n",
        "  \n",
        "  model.train() #Changes the model to train mode. All the require_grad are set to true.\n",
        "  \n",
        "  for epoch in range(EPOCHS):\n",
        "    correct = 0\n",
        "    for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
        "      \n",
        "      #Move data to device\n",
        "      var_X_batch = Variable(X_batch).to(device) \n",
        "      var_y_batch = Variable(y_batch).to(device)\n",
        "      # print(var_X_batch.size())\n",
        "      \n",
        "      ## Forward Pass!\n",
        "      output = model(var_X_batch)\n",
        "\n",
        "      # print(output)\n",
        "      # print(output.size(), var_y_batch.size())\n",
        "      \n",
        "      ## Calculate the loss incurred\n",
        "      loss = lossF (output, var_y_batch)\n",
        "      \n",
        "      ## BackProp: Computes all gradients.\n",
        "      loss.backward()\n",
        "      \n",
        "      ## Gradient Descent Step (Adam)\n",
        "      optim.step()\n",
        "      optim.zero_grad() # This is important because PyTorch keeps on adding to the original value of gradient.\n",
        "\n",
        "      ## Gets the predictions. From probablities (the digit with highest probablity is the prediction) \n",
        "      predicted = torch.max(output.data, axis = 1).indices\n",
        "      \n",
        "      # print(predicted)\n",
        "\n",
        "      ## Calculates the number of correct predictions in a batch\n",
        "      correct += (predicted == var_y_batch).sum()\n",
        "\n",
        "      if (batch_idx % 200) == 0:\n",
        "          print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
        "                    epoch, batch_idx*len(X_batch), len(train_loader.dataset), 100.*batch_idx / len(train_loader), loss.item(), float(correct*100) / float(BATCH_SIZE*(batch_idx+1))))\n",
        "\n",
        "\n",
        "\n",
        "def test(model, test_loader):\n",
        "    \"\"\"\n",
        "    Change the value of correct to contain the number of correctly classified test examples out of the 10000 example in test_loader.\n",
        "    \"\"\"\n",
        "    correct = 0 \n",
        "    # Put your code here: \n",
        "    # __begin\n",
        "    \n",
        "  \n",
        "    #__end\n",
        "    print(\"Test accuracy:{:.3f}% \".format( float(correct * 100) / (len(test_loader))))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIP2LRsXUBfu",
        "colab_type": "text"
      },
      "source": [
        "Running the following cell will start training of the \"net\". \n",
        "\n",
        "Note: Any decent bugfree conv-net should easily reach an accuracy of atleast 96%. If you are unable to do so, try improving the network architecture and/or try different training rate or longer training (higher EPOCHS)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snnWa2Cx46lt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train (net, train_loader, EPOCHS = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inxDDeCyU6_H",
        "colab_type": "text"
      },
      "source": [
        "Run the test function that you defined above! \n",
        "\n",
        "\n",
        "Note: You should easily reach 95%.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU2zLhyg92bu",
        "colab_type": "code",
        "outputId": "11d811b0-0311-489c-96b7-5778a4000db8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test(net, test_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy:98.600% \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O_fyaSRRd60",
        "colab_type": "text"
      },
      "source": [
        "(Bonus) **TASK 2**\n",
        "\n",
        "Before getting started read [this article](https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html) on Deep Dream.\n",
        "\n",
        "Description of the task: Now we have trained the network to classify all the digits from 0 to 10. But is there a way to visualize what the network has learnt? \n",
        "\n",
        "Well how about we learn (by backprop + Gradient Descent) the input image after fixing the expected output and all the network parameters. In other words say we want to visualize what 7 looks like to the network. Then we will do the following:\n",
        "1. Initialize image tensor as im (maybe with all zeros).\n",
        "2. Pass the image through the network.\n",
        "3. Compute the loss with output of the net and expected output of 7.\n",
        "4. Run backpropogation upto the image tensor.\n",
        "5. Update the image using the update rule. (Specified by torch.optim object)\n",
        "\n",
        "\n",
        "Remember that while creating the optimization object (torch.optim object) you have to pass to it a list of parameters to be optimized. Which in this case won't be model.parameters() but rather [im, ].\n",
        "\n",
        "Note: We are not using training or test data anywhere here!\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CT2FsVPEyYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_im(model, digit = 7 ,iters = 1000, lossF = None):\n",
        "  \"\"\"\n",
        "  Train the input image to match the <digit>. Run <iters> iterations of Gradient Descent.  \n",
        "  \"\"\"\n",
        "  im = torch.zeros_like(train_data[1][0]).view(1, 1, 28, 28).to(device)\n",
        "  im = Variable(im, requires_grad = True)\n",
        "  digit = Variable(torch.tensor(digit)).to(device).view(1)\n",
        "  # Put your code here: \n",
        "  # __begin\n",
        "\n",
        "\n",
        "  #__end\n",
        "    \n",
        "  return im"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hcvC3TlR3Zs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Let's run our function for 7 and see what image we get.\n",
        "\n",
        "im = train_im (net, train_loader, digit=7)\n",
        "im = np.asarray(im.view(28, 28).cpu().detach())\n",
        "plt.imshow(im)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neETLR1Ub0my",
        "colab_type": "text"
      },
      "source": [
        "In the the following cell we will run the function for all the digits from 0 to 9 and print the outputs! \n",
        "\n",
        "Enjoy you are done!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPoDpHbvZ9TE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range (10):\n",
        "  im = train_im (net, train_loader, digit=i, iters=1000)\n",
        "  im = np.asarray(im.view(28, 28).cpu().detach())\n",
        "  print (i)\n",
        "  plt.imshow(im)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrgpVwIlqwPR",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}